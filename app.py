"""ãƒ©ã‚¤ãƒ–é…ä¿¡ãƒãƒ£ãƒƒãƒˆåˆ†æãƒ„ãƒ¼ãƒ« - Streamlitãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª"""
import streamlit as st
import tempfile
import os
import pickle
import glob
import time
import base64
import sys
import re
import pandas as pd
from datetime import datetime
from typing import Dict, Optional
from utils.csv_processor import (
    load_csv,
    validate_and_process_data,
    extract_questions
)
from utils.ai_analyzer import analyze_all_comments
from utils.google_sheets import (
    calculate_statistics,
    calculate_question_statistics
)
from utils.api_key_manager import render_api_key_input, get_active_api_key
from config import COMPANIES, DEFAULT_COMPANY, get_company_config


def inject_custom_css():
    """ã‚«ã‚¹ã‚¿ãƒ CSSã‚’æ³¨å…¥"""
    css_file_path = os.path.join(os.path.dirname(__file__), "styles", "custom.css")

    if os.path.exists(css_file_path):
        with open(css_file_path, "r", encoding="utf-8") as f:
            css = f.read()
        st.markdown(f"<style>{css}</style>", unsafe_allow_html=True)


def remove_live_name_from_filename(filename: str) -> str:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã€Œ_(ãƒ©ã‚¤ãƒ–é…ä¿¡ã®åå‰)ã€ã®éƒ¨åˆ†ã‚’å‰Šé™¤
    
    Args:
        filename: å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«å
        
    Returns:
        ãƒ©ã‚¤ãƒ–é…ä¿¡åã‚’å‰Šé™¤ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«å
    """
    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: _(...) ã¾ãŸã¯ _(...)ï¼ˆåŠè§’æ‹¬å¼§ã®ã¿ï¼‰
    filename = re.sub(r'_\s*\([^)]*\)', '', filename)
    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ï¼ˆ...ï¼‰ ã¾ãŸã¯ ï¼ˆ...ï¼‰ï¼ˆå…¨è§’æ‹¬å¼§ã®ã¿ï¼‰
    filename = re.sub(r'[_\sã€€]ï¼ˆ[^ï¼‰]*ï¼‰', '', filename)
    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã¾ãŸã¯ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ + åŠè§’é–‹ãæ‹¬å¼§ + ä»»æ„ã®æ–‡å­— + å…¨è§’é–‰ã˜æ‹¬å¼§ï¼ˆæ··åœ¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    filename = re.sub(r'[_\sã€€]\([^ï¼‰]*ï¼‰', '', filename)
    # ãƒ‘ã‚¿ãƒ¼ãƒ³4: å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã¾ãŸã¯ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ + å…¨è§’é–‹ãæ‹¬å¼§ + ä»»æ„ã®æ–‡å­— + åŠè§’é–‰ã˜æ‹¬å¼§ï¼ˆæ··åœ¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    filename = re.sub(r'[_\sã€€]ï¼ˆ[^)]*\)', '', filename)
    # ãƒ‘ã‚¿ãƒ¼ãƒ³5: æœ«å°¾ã®ç©ºç™½ã‚’å‰Šé™¤
    filename = filename.strip()
    return filename


def calculate_api_cost(prompt_tokens: int, completion_tokens: int) -> float:
    """
    APIä½¿ç”¨æ–™é‡‘ã‚’è¨ˆç®—ï¼ˆGPT-4o-miniï¼‰
    
    Args:
        prompt_tokens: å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        completion_tokens: å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        
    Returns:
        æ¨å®šè²»ç”¨ï¼ˆãƒ‰ãƒ«ï¼‰
    """
    INPUT_COST_PER_MILLION = 0.15  # $0.15 per 1M tokens
    OUTPUT_COST_PER_MILLION = 0.60  # $0.60 per 1M tokens
    
    input_cost = (prompt_tokens / 1_000_000) * INPUT_COST_PER_MILLION
    output_cost = (completion_tokens / 1_000_000) * OUTPUT_COST_PER_MILLION
    
    return input_cost + output_cost


def create_download_link(data: bytes, filename: str, mime_type: str) -> str:
    """
    Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’ä½œæˆ
    
    Args:
        data: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒã‚¤ãƒˆï¼‰
        filename: ãƒ•ã‚¡ã‚¤ãƒ«å
        mime_type: MIMEã‚¿ã‚¤ãƒ—
        
    Returns:
        HTMLãƒªãƒ³ã‚¯æ–‡å­—åˆ—
    """
    b64 = base64.b64encode(data).decode()
    href = f'<a href="data:{mime_type};base64,{b64}" download="{filename}" style="color: #1f77b4; text-decoration: underline; font-weight: bold;">ğŸ“¥ {filename}</a>'
    return href


def add_statistics_to_csv(df: pd.DataFrame, stats: Dict, is_question: bool = False, question_stats: Optional[Dict] = None) -> str:
    """
    CSVã«çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ ï¼ˆã‚°ãƒ©ãƒ•ä½œæˆã—ã‚„ã™ã„ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰
    
    Args:
        df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        stats: çµ±è¨ˆæƒ…å ±
        is_question: è³ªå•CSVã‹ã©ã†ã‹
        question_stats: è³ªå•çµ±è¨ˆæƒ…å ±ï¼ˆè³ªå•CSVã®å ´åˆã®ã¿ï¼‰
        
    Returns:
        çµ±è¨ˆæƒ…å ±ãŒè¿½åŠ ã•ã‚ŒãŸCSVæ–‡å­—åˆ—
    """
    # çµ±è¨ˆæƒ…å ±ã‚’CSVå½¢å¼ã®æ–‡å­—åˆ—ã¨ã—ã¦ä½œæˆ
    stats_lines = []
    
    if is_question and question_stats:
        # è³ªå•CSVç”¨ã®çµ±è¨ˆæƒ…å ±
        stats_lines.append("çµ±è¨ˆæƒ…å ±")
        stats_lines.append(f"è³ªå•ã‚³ãƒ¡ãƒ³ãƒˆä»¶æ•°,{question_stats.get('total_questions', 0)}")
        stats_lines.append(f"è³ªå•å›ç­”ç‡,{question_stats.get('answer_rate', 0.0):.1f}%")
        stats_lines.append("")  # ç©ºè¡Œ
        stats_lines.append("è³ªå•ã‚³ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿")
    else:
        # ãƒ¡ã‚¤ãƒ³CSVç”¨ã®çµ±è¨ˆæƒ…å ±
        stats_lines.append("çµ±è¨ˆæƒ…å ±")
        stats_lines.append(f"å…¨ã‚³ãƒ¡ãƒ³ãƒˆä»¶æ•°,{stats.get('total_comments', 0)}")
        stats_lines.append("")  # ç©ºè¡Œ
        stats_lines.append("ãƒãƒ£ãƒƒãƒˆã®å±æ€§åˆ¥ä»¶æ•°")
        stats_lines.append("å±æ€§,ä»¶æ•°")
        for attr, count in stats.get('attribute_counts', {}).items():
            stats_lines.append(f"{attr},{count}")
        stats_lines.append("")  # ç©ºè¡Œ
        stats_lines.append("ãƒãƒ£ãƒƒãƒˆæ„Ÿæƒ…åˆ¥ä»¶æ•°")
        stats_lines.append("æ„Ÿæƒ…,ä»¶æ•°")
        for sentiment, count in stats.get('sentiment_counts', {}).items():
            stats_lines.append(f"{sentiment},{count}")
        stats_lines.append("")  # ç©ºè¡Œ
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆæ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½5åï¼‰
        if 'username' in df.columns:
            user_counts = df['username'].value_counts().head(5)
            stats_lines.append("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆæ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            stats_lines.append("ãƒ¦ãƒ¼ã‚¶ãƒ¼å,ã‚³ãƒ¡ãƒ³ãƒˆæ•°")
            for username, count in user_counts.items():
                stats_lines.append(f"{username},{count}")
            stats_lines.append("")  # ç©ºè¡Œ
        
        stats_lines.append("ã‚³ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿")
    
    # çµ±è¨ˆæƒ…å ±ã‚’CSVæ–‡å­—åˆ—ã«å¤‰æ›
    stats_csv = "\n".join(stats_lines)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’CSVæ–‡å­—åˆ—ã«å¤‰æ›
    data_csv = df.to_csv(index=False)
    
    # çµ±è¨ˆæƒ…å ±ã¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
    combined_csv = stats_csv + "\n" + data_csv
    
    return combined_csv


def format_remaining_time(seconds: float) -> str:
    """
    æ®‹ã‚Šæ™‚é–“ï¼ˆç§’ï¼‰ã‚’ã€Œã‚ã¨â—¯åˆ†â—¯ç§’ã€å½¢å¼ã«å¤‰æ›
    
    Args:
        seconds: æ®‹ã‚Šæ™‚é–“ï¼ˆç§’ï¼‰
        
    Returns:
        ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ®‹ã‚Šæ™‚é–“ã®æ–‡å­—åˆ—
    """
    if seconds < 0:
        return "ã‚ã¨0ç§’"
    
    total_seconds = int(seconds)
    
    # 1æ™‚é–“ä»¥ä¸Šã®å ´åˆ
    if total_seconds >= 3600:
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        return f"ã‚ã¨{hours}æ™‚é–“{minutes}åˆ†"
    
    # 1åˆ†ä»¥ä¸Š1æ™‚é–“æœªæº€ã®å ´åˆ
    elif total_seconds >= 60:
        minutes = total_seconds // 60
        secs = total_seconds % 60
        return f"ã‚ã¨{minutes}åˆ†{secs}ç§’"
    
    # 1åˆ†æœªæº€ã®å ´åˆ
    else:
        return f"ã‚ã¨{total_seconds}ç§’"


def main():
    st.set_page_config(
        page_title="ãƒ©ã‚¤ãƒ–é…ä¿¡ãƒãƒ£ãƒƒãƒˆåˆ†æãƒ„ãƒ¼ãƒ«",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # ã‚«ã‚¹ã‚¿ãƒ CSSã‚’æ³¨å…¥
    inject_custom_css()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼: APIã‚­ãƒ¼è¨­å®š
    with st.sidebar:
        has_api_key = render_api_key_input()
        st.divider()

    # æ©Ÿèƒ½é¸æŠï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
    st.sidebar.title("æ©Ÿèƒ½é¸æŠ")
    selected_feature = st.sidebar.radio(
        "ä½¿ç”¨ã™ã‚‹æ©Ÿèƒ½ã‚’é¸æŠã—ã¦ãã ã•ã„",
        ["ã‚³ãƒ¡ãƒ³ãƒˆåˆ†ææ©Ÿèƒ½", "è³ªå•å›ç­”åˆ¤å®šæ©Ÿèƒ½"],
        index=0
    )

    # ä¼æ¥­é¸æŠï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
    st.sidebar.title("ä¼æ¥­é¸æŠ")
    company_names = list(COMPANIES.keys())
    if "selected_company" not in st.session_state:
        st.session_state.selected_company = DEFAULT_COMPANY
    
    selected_company = st.sidebar.selectbox(
        "ä¼æ¥­ã‚’é¸æŠã—ã¦ãã ã•ã„",
        company_names,
        index=company_names.index(st.session_state.selected_company) if st.session_state.selected_company in company_names else 0
    )
    
    # ä¼æ¥­é¸æŠãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’æ›´æ–°
    if selected_company != st.session_state.selected_company:
        st.session_state.selected_company = selected_company
        # åˆ†æçµæœã‚’ã‚¯ãƒªã‚¢ï¼ˆä¼æ¥­ãŒå¤‰ã‚ã£ãŸã‚‰å†åˆ†æãŒå¿…è¦ï¼‰
        if "analysis_complete" in st.session_state:
            st.session_state.analysis_complete = False
        if "processed_data" in st.session_state:
            st.session_state.processed_data = None
    
    # ç¾åœ¨ã®ä¼æ¥­è¨­å®šã‚’å–å¾—
    company_config = get_company_config(selected_company)

    st.title("ãƒ©ã‚¤ãƒ–é…ä¿¡ãƒãƒ£ãƒƒãƒˆåˆ†æãƒ„ãƒ¼ãƒ«")
    st.markdown(f"**ä¼æ¥­å**: {company_config['name']}")

    # APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®è­¦å‘Š
    if not has_api_key:
        st.warning("åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯APIã‚­ãƒ¼ã®è¨­å®šãŒå¿…è¦ã§ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.info("[OpenAI APIã‚­ãƒ¼ã®å–å¾—ã¯ã“ã¡ã‚‰](https://platform.openai.com/api-keys)")
        st.stop()

    # é¸æŠã•ã‚ŒãŸæ©Ÿèƒ½ã«å¿œã˜ã¦ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
    if selected_feature == "è³ªå•å›ç­”åˆ¤å®šæ©Ÿèƒ½":
        # è³ªå•å›ç­”åˆ¤å®šæ©Ÿèƒ½ã®ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
        show_question_answer_page()
        return
    
    # æ—¢å­˜ã®ã‚³ãƒ¡ãƒ³ãƒˆåˆ†ææ©Ÿèƒ½ã®ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
    show_comment_analysis_page()


def show_comment_analysis_page():
    """ã‚³ãƒ¡ãƒ³ãƒˆåˆ†ææ©Ÿèƒ½ã®ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
    if "processed_data" not in st.session_state:
        st.session_state.processed_data = None
    if "analysis_complete" not in st.session_state:
        st.session_state.analysis_complete = False
    if "analysis_save_path" not in st.session_state:
        st.session_state.analysis_save_path = None
    if "analysis_original_df" not in st.session_state:
        st.session_state.analysis_original_df = None
    if "analysis_cancelled" not in st.session_state:
        st.session_state.analysis_cancelled = False
    if "csv_main_data" not in st.session_state:
        st.session_state.csv_main_data = None
    if "csv_main_filename" not in st.session_state:
        st.session_state.csv_main_filename = None
    if "csv_question_data" not in st.session_state:
        st.session_state.csv_question_data = None
    if "csv_question_filename" not in st.session_state:
        st.session_state.csv_question_filename = None
    if "stats_data" not in st.session_state:
        st.session_state.stats_data = None
    if "question_stats_data" not in st.session_state:
        st.session_state.question_stats_data = None
    if "question_df_data" not in st.session_state:
        st.session_state.question_df_data = None
    if "uploaded_csv_filename" not in st.session_state:
        st.session_state.uploaded_csv_filename = ""
    if "api_usage" not in st.session_state:
        st.session_state.api_usage = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
            "estimated_cost_usd": 0.0
        }
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼: APIä½¿ç”¨çŠ¶æ³ï¼ˆåˆ†æå®Œäº†æ™‚ã®ã¿è¡¨ç¤ºï¼‰
    with st.sidebar:
        if st.session_state.get("analysis_complete") and st.session_state.get("api_usage") and st.session_state.api_usage["total_tokens"] > 0:
            st.divider()
            st.subheader("APIä½¿ç”¨çŠ¶æ³")
            usage = st.session_state.api_usage
            st.metric("ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°", f"{usage['total_tokens']:,}")
            st.write(f"å…¥åŠ›: {usage['prompt_tokens']:,} ãƒˆãƒ¼ã‚¯ãƒ³")
            st.write(f"å‡ºåŠ›: {usage['completion_tokens']:,} ãƒˆãƒ¼ã‚¯ãƒ³")
            st.metric("æ¨å®šè²»ç”¨", f"${usage['estimated_cost_usd']:.4f}")
            st.caption("ãƒ¢ãƒ‡ãƒ«: GPT-4o-mini")
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.header("1. CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    st.info("ğŸ’¡ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã‚¢ãƒ³ãƒ‰ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ã‹ã€ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    uploaded_file = st.file_uploader(
        "ğŸ“„ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—å¯ï¼‰",
        type=["csv"],
        help="CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã‚¢ãƒ³ãƒ‰ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ã‹ã€ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚å¿…è¦ãªåˆ—: guest_id, username, original_text, inserted_at"
    )
    
    if uploaded_file is not None:
        try:
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä¿å­˜ï¼ˆæ‹¡å¼µå­ãªã—ï¼‰
            uploaded_filename = uploaded_file.name
            if uploaded_filename.endswith('.csv'):
                uploaded_filename_base = uploaded_filename[:-4]  # .csvã‚’é™¤å»
            else:
                uploaded_filename_base = uploaded_filename
            # ãƒ©ã‚¤ãƒ–é…ä¿¡åã‚’å‰Šé™¤
            uploaded_filename_base = remove_live_name_from_filename(uploaded_filename_base)
            st.session_state.uploaded_csv_filename = uploaded_filename_base
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = tmp_file.name
            
            # CSVã‚’èª­ã¿è¾¼ã‚“ã§å‡¦ç†
            with st.spinner("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™..."):
                df = load_csv(tmp_path)
                df = validate_and_process_data(df)
                st.session_state.processed_data = df
                st.session_state.analysis_complete = False
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.success(f"âœ“ {len(df)}ä»¶ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.dataframe(df.head(10), use_container_width=True)
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            os.unlink(tmp_path)
            
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return
    
    # AIåˆ†æ
    if st.session_state.processed_data is not None and not st.session_state.analysis_complete:
        st.header("2. AIåˆ†æ")
        
        df = st.session_state.processed_data.copy()
        
        # åˆ†æé€”ä¸­ã®çµæœãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆPCã‚¹ãƒªãƒ¼ãƒ—å¯¾ç­–ï¼‰
        analysis_resume_available = False
        saved_count = 0
        
        # ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ¤œç´¢ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ãªã„å ´åˆã§ã‚‚æ¤œç´¢ï¼‰
        if not st.session_state.analysis_save_path:
            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æœ€æ–°ã®ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            save_dir = tempfile.gettempdir()
            save_files = glob.glob(os.path.join(save_dir, "analysis_save_*.pkl"))
            if save_files:
                # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
                latest_file = max(save_files, key=os.path.getmtime)
                st.session_state.analysis_save_path = latest_file
        
        if st.session_state.analysis_save_path and os.path.exists(st.session_state.analysis_save_path):
            try:
                with open(st.session_state.analysis_save_path, 'rb') as f:
                    saved_data = pickle.load(f)
                    if saved_data:
                        if isinstance(saved_data, list):
                            saved_count = len(saved_data)
                        elif isinstance(saved_data, pd.DataFrame):
                            saved_count = len(saved_data)
                        if saved_count > 0:
                            analysis_resume_available = True
            except Exception:
                pass
        
        if analysis_resume_available:
            st.warning(f"âš ï¸ åˆ†æãŒé€”ä¸­ã§ä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚{saved_count}ä»¶ã®åˆ†æçµæœãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ç¶šãã‹ã‚‰å†é–‹ã§ãã¾ã™ã€‚")
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ç¶šãã‹ã‚‰å†é–‹", type="primary"):
                    st.session_state.analysis_resume = True
                    # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç¢ºä¿
                    if st.session_state.analysis_original_df is None:
                        st.session_state.analysis_original_df = df.copy()
                    st.rerun()
            with col2:
                if st.button("æœ€åˆã‹ã‚‰é–‹å§‹"):
                    # ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    if st.session_state.analysis_save_path and os.path.exists(st.session_state.analysis_save_path):
                        try:
                            os.remove(st.session_state.analysis_save_path)
                        except Exception:
                            pass
                    st.session_state.analysis_resume = False
                    st.session_state.analysis_save_path = None
                    st.session_state.analysis_original_df = None
                    st.rerun()
        
        # åˆ†æé–‹å§‹ãƒ»ä¸­æ–­ãƒœã‚¿ãƒ³
        col1, col2 = st.columns(2)
        with col1:
            start_analysis = st.button("åˆ†æã‚’é–‹å§‹", type="primary")
        with col2:
            cancel_analysis = st.button("åˆ†æã‚’ä¸­æ–­", type="secondary", disabled=st.session_state.analysis_complete)
        
        # ä¸­æ–­ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆ
        if cancel_analysis:
            st.session_state.analysis_cancelled = True
            st.warning("âš ï¸ åˆ†æã®ä¸­æ–­ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã¾ã—ãŸã€‚ç¾åœ¨å‡¦ç†ä¸­ã®ã‚³ãƒ¡ãƒ³ãƒˆãŒå®Œäº†æ¬¡ç¬¬ã€åˆ†æãŒä¸­æ–­ã•ã‚Œã¾ã™ã€‚")
        
        # åˆ†æé–‹å§‹
        if start_analysis or st.session_state.get("analysis_resume", False):
            # APIã‚­ãƒ¼äº‹å‰ãƒã‚§ãƒƒã‚¯
            try:
                from config import get_openai_api_key
                if not get_openai_api_key():
                    st.error("OpenAI APIã‚­ãƒ¼ãŒæœªè¨­å®šã§ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                    return
            except Exception:
                st.error("APIã‚­ãƒ¼ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å†åº¦ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                return

            # ä¸­æ–­ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state.analysis_cancelled = False
            # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆæ–°ã—ã„åˆ†æé–‹å§‹æ™‚ã®ã¿ï¼‰
            if start_analysis:
                st.session_state.api_usage = {
                    "prompt_tokens": 0,
                    "completion_tokens": 0,
                    "total_tokens": 0,
                    "estimated_cost_usd": 0.0
                }
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®šï¼ˆPCã‚¹ãƒªãƒ¼ãƒ—å¯¾ç­–ï¼‰
            if not st.session_state.analysis_save_path:
                save_dir = tempfile.gettempdir()
                save_filename = f"analysis_save_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
                st.session_state.analysis_save_path = os.path.join(save_dir, save_filename)
            
            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿å­˜ï¼ˆå†é–‹æ™‚ã«ä½¿ç”¨ï¼‰
            if st.session_state.analysis_original_df is None:
                st.session_state.analysis_original_df = df.copy()
            else:
                df = st.session_state.analysis_original_df.copy()
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²
            start_time = time.time()
            
            def update_progress(current, total):
                progress = current / total
                progress_bar.progress(progress)
                
                # çµŒéæ™‚é–“ã®è¨ˆç®—
                elapsed_time = time.time() - start_time
                elapsed_seconds = int(elapsed_time)
                hours = elapsed_seconds // 3600
                minutes = (elapsed_seconds % 3600) // 60
                seconds = elapsed_seconds % 60
                elapsed_str = f"{hours:02d}:{minutes:02d}:{seconds:02d}"
                
                # äºˆæƒ³å®Œäº†æ™‚é–“ã®è¨ˆç®—
                if current > 0:
                    avg_time_per_item = elapsed_time / current
                    remaining_items = total - current
                    estimated_remaining = avg_time_per_item * remaining_items
                    estimated_str = format_remaining_time(estimated_remaining)
                    
                    status_text.text(
                        f"é€²è¡Œä¸­: {current}/{total} ({progress*100:.1f}%)\n"
                        f"çµŒéæ™‚é–“: {elapsed_str}\n"
                        f"äºˆæƒ³å®Œäº†æ™‚é–“: {estimated_str}"
                    )
                else:
                    status_text.text(f"é€²è¡Œä¸­: {current}/{total} ({progress*100:.1f}%)")
            
            def save_intermediate_results(action, results=None):
                """ä¸­é–“çµæœã‚’ä¿å­˜ï¼ˆPCã‚¹ãƒªãƒ¼ãƒ—å¯¾ç­–ï¼‰"""
                save_path = st.session_state.analysis_save_path
                
                if action == "save" and results is not None:
                    # çµæœã‚’ä¿å­˜
                    try:
                        with open(save_path, 'wb') as f:
                            pickle.dump(results, f)
                    except Exception as e:
                        print(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                elif action == "load":
                    # ä¿å­˜ã•ã‚ŒãŸçµæœã‚’èª­ã¿è¾¼ã‚€
                    if save_path and os.path.exists(save_path):
                        try:
                            with open(save_path, 'rb') as f:
                                saved_results = pickle.load(f)
                                return saved_results
                        except Exception as e:
                            print(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    return None
                elif action == "clear":
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    if save_path and os.path.exists(save_path):
                        try:
                            os.remove(save_path)
                        except Exception:
                            pass
            
            def check_cancel():
                """ä¸­æ–­ãƒ•ãƒ©ã‚°ã‚’ãƒã‚§ãƒƒã‚¯"""
                return st.session_state.get("analysis_cancelled", False)
            
            try:
                # AIåˆ†æå®Ÿè¡Œï¼ˆçµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½¿ç”¨ï¼š50%é«˜é€ŸåŒ–ï¼‰
                with st.spinner("AIåˆ†æã‚’å®Ÿè¡Œä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„..."):
                    analysis_result = analyze_all_comments(df, update_progress, save_intermediate_results, check_cancel)
                
                # åˆ†æçµæœã‹ã‚‰DataFrameã¨ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡æƒ…å ±ã‚’å–å¾—
                if isinstance(analysis_result, dict):
                    analyzed_df = analysis_result["df"]
                    api_usage_info = analysis_result.get("api_usage", {})
                else:
                    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€DataFrameãŒç›´æ¥è¿”ã•ã‚ŒãŸå ´åˆ
                    analyzed_df = analysis_result
                    api_usage_info = {}
                
                st.session_state.processed_data = analyzed_df
                st.session_state.analysis_complete = True
                st.session_state.analysis_resume = False
                st.session_state.analysis_original_df = None
                st.session_state.analysis_cancelled = False  # å®Œäº†æ™‚ã«ä¸­æ–­ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢
                
                # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                if api_usage_info:
                    prompt_tokens = api_usage_info.get("prompt_tokens", 0)
                    completion_tokens = api_usage_info.get("completion_tokens", 0)
                    total_tokens = api_usage_info.get("total_tokens", 0)
                    estimated_cost = calculate_api_cost(prompt_tokens, completion_tokens)
                    
                    st.session_state.api_usage = {
                        "prompt_tokens": prompt_tokens,
                        "completion_tokens": completion_tokens,
                        "total_tokens": total_tokens,
                        "estimated_cost_usd": estimated_cost
                    }
                    
                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ãŒ0ã®å ´åˆã®åŸå› ç‰¹å®šç”¨ï¼‰
                    if total_tokens == 0:
                        st.warning(f"âš ï¸ ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ãŒ0ã§ã™ã€‚åˆ†æã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆæ•°: {len(analyzed_df)}")
                else:
                    # api_usage_infoãŒç©ºã®å ´åˆã®è­¦å‘Š
                    st.warning("âš ï¸ APIä½¿ç”¨é‡æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                
                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ç”Ÿæˆï¼ˆåˆ†æå®Œäº†æ™‚ã«è‡ªå‹•å®Ÿè¡Œï¼‰
                try:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’å«ã‚€ï¼‰
                    uploaded_filename_base = st.session_state.get("uploaded_csv_filename", "")
                    if uploaded_filename_base:
                        default_file_title = f"ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æ_{uploaded_filename_base}"
                    else:
                        default_file_title = "ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æ"
                    
                    # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ï¼ˆå¾Œã§CSVã«è¿½åŠ ã™ã‚‹ãŸã‚ï¼‰
                    temp_stats = calculate_statistics(analyzed_df)
                    question_df_temp = extract_questions(analyzed_df)
                    question_df_temp["å›ç­”çŠ¶æ³"] = "æœªå›ç­”"
                    temp_question_stats = calculate_question_statistics(question_df_temp)
                    
                    # ãƒ¡ã‚¤ãƒ³CSVï¼ˆå…¨ã‚³ãƒ¡ãƒ³ãƒˆï¼‰ã‚’ä½œæˆ
                    # guest_idã‚’å‰Šé™¤ã—ã€inserted_atã‚’ã€Œé…ä¿¡æ™‚é–“ã€ã«ãƒªãƒãƒ¼ãƒ ã—ã¦ä¸€ç•ªå·¦åˆ—ã«ç§»å‹•
                    main_df = analyzed_df.copy()
                    if 'guest_id' in main_df.columns:
                        main_df = main_df.drop(columns=['guest_id'])
                    if 'inserted_at' in main_df.columns:
                        main_df = main_df.rename(columns={'inserted_at': 'é…ä¿¡æ™‚é–“'})
                        # é…ä¿¡æ™‚é–“ã‚’ä¸€ç•ªå·¦åˆ—ã«ç§»å‹•
                        cols = ['é…ä¿¡æ™‚é–“'] + [col for col in main_df.columns if col != 'é…ä¿¡æ™‚é–“']
                        main_df = main_df[cols]
                    
                    # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
                    csv_main = add_statistics_to_csv(main_df, temp_stats, is_question=False)
                    st.session_state.csv_main_data = csv_main.encode('utf-8-sig')
                    st.session_state.csv_main_filename = f"{default_file_title}_ãƒ¡ã‚¤ãƒ³.csv"
                    
                    # è³ªå•CSVï¼ˆè³ªå•ã‚³ãƒ¡ãƒ³ãƒˆã®ã¿ï¼‰ã‚’ä½œæˆ
                    if len(question_df_temp) > 0:
                        # guest_idã‚’å‰Šé™¤ã—ã€åˆ—ã®é †åºã‚’èª¿æ•´ï¼ˆAåˆ—: å›ç­”çŠ¶æ³ã€Båˆ—: é…ä¿¡æ™‚é–“ï¼‰
                        question_csv_df = question_df_temp.copy()
                        if 'guest_id' in question_csv_df.columns:
                            question_csv_df = question_csv_df.drop(columns=['guest_id'])
                        if 'inserted_at' in question_csv_df.columns:
                            question_csv_df = question_csv_df.rename(columns={'inserted_at': 'é…ä¿¡æ™‚é–“'})
                        # åˆ—ã®é †åº: å›ç­”çŠ¶æ³ã€é…ä¿¡æ™‚é–“ã€ãã®ä»–
                        if 'å›ç­”çŠ¶æ³' in question_csv_df.columns and 'é…ä¿¡æ™‚é–“' in question_csv_df.columns:
                            other_cols = [col for col in question_csv_df.columns if col not in ['å›ç­”çŠ¶æ³', 'é…ä¿¡æ™‚é–“']]
                            cols = ['å›ç­”çŠ¶æ³', 'é…ä¿¡æ™‚é–“'] + other_cols
                            question_csv_df = question_csv_df[cols]
                        
                        # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
                        csv_question = add_statistics_to_csv(question_csv_df, temp_stats, is_question=True, question_stats=temp_question_stats)
                        st.session_state.csv_question_data = csv_question.encode('utf-8-sig')
                        st.session_state.csv_question_filename = f"{default_file_title}_è³ªå•.csv"
                except Exception as e:
                    # CSVç”Ÿæˆã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼ˆå¾Œã§å†ç”Ÿæˆå¯èƒ½ï¼‰
                    print(f"CSVè‡ªå‹•ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                
                # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                question_df = extract_questions(analyzed_df)
                question_df["å›ç­”çŠ¶æ³"] = "æœªå›ç­”"
                st.session_state.stats_data = calculate_statistics(analyzed_df)
                st.session_state.question_stats_data = calculate_question_statistics(question_df)
                st.session_state.question_df_data = question_df
                
                progress_bar.progress(1.0)
                status_text.text("âœ“ åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                st.success("åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                
                # åˆ†æçµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                st.subheader("åˆ†æçµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.dataframe(analyzed_df.head(10), use_container_width=True)
                
            except KeyboardInterrupt:
                # ä¸­æ–­ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã•ã‚ŒãŸå ´åˆ
                st.session_state.analysis_cancelled = True
                st.warning("âš ï¸ åˆ†æãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
                st.info("ğŸ’¡ ã€Œç¶šãã‹ã‚‰å†é–‹ã€ãƒœã‚¿ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€ä¸­æ–­ã—ãŸç®‡æ‰€ã‹ã‚‰åˆ†æã‚’å†é–‹ã§ãã¾ã™ã€‚")
                # ä¸­æ–­ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã€æ¬¡å›ã®å†é–‹æ™‚ã«å•é¡ŒãŒãªã„ã‚ˆã†ã«ã™ã‚‹
                st.session_state.analysis_cancelled = False
                st.rerun()
            except Exception as e:
                # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
                error_message = str(e)
                if "ä¸­æ–­" in error_message or "KeyboardInterrupt" in error_message:
                    # ä¸­æ–­é–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
                    st.session_state.analysis_cancelled = True
                    st.warning("âš ï¸ åˆ†æãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
                    st.info("ğŸ’¡ ã€Œç¶šãã‹ã‚‰å†é–‹ã€ãƒœã‚¿ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€ä¸­æ–­ã—ãŸç®‡æ‰€ã‹ã‚‰åˆ†æã‚’å†é–‹ã§ãã¾ã™ã€‚")
                    st.session_state.analysis_cancelled = False
                    st.rerun()
                else:
                    # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
                    st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {error_message}")
                    st.info("ğŸ’¡ PCãŒã‚¹ãƒªãƒ¼ãƒ—ã—ãŸå ´åˆã¯ã€ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ã€Œç¶šãã‹ã‚‰å†é–‹ã€ãƒœã‚¿ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
                    import traceback
                    with st.expander("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±"):
                        st.code(traceback.format_exc())
                    return
    
    # ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›
    if st.session_state.analysis_complete and st.session_state.processed_data is not None:
        st.header("3. ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›")
        
        # çµ±è¨ˆæƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰å–å¾—ï¼ˆãªã‘ã‚Œã°è¨ˆç®—ï¼‰
        if st.session_state.stats_data is None:
            df = st.session_state.processed_data.copy()
            question_df = extract_questions(df)
            question_df["å›ç­”çŠ¶æ³"] = "æœªå›ç­”"
            st.session_state.stats_data = calculate_statistics(df)
            st.session_state.question_stats_data = calculate_question_statistics(question_df)
            st.session_state.question_df_data = question_df
        
        df = st.session_state.processed_data.copy()
        stats = st.session_state.stats_data
        question_stats = st.session_state.question_stats_data
        question_df = st.session_state.question_df_data
        
        # çµ±è¨ˆæƒ…å ±ã‚’å¸¸ã«è¡¨ç¤ºï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã‚‚è¡¨ç¤ºã•ã‚Œã‚‹ï¼‰
        st.subheader("çµ±è¨ˆæƒ…å ±")
        
        stat_col1, stat_col2 = st.columns(2)
        
        with stat_col1:
            st.metric("å…¨ã‚³ãƒ¡ãƒ³ãƒˆä»¶æ•°", stats["total_comments"])
            st.write("**ãƒãƒ£ãƒƒãƒˆã®å±æ€§åˆ¥ä»¶æ•°**")
            for attr, count in stats["attribute_counts"].items():
                st.write(f"- {attr}: {count}ä»¶")
        
        with stat_col2:
            if len(question_df) > 0:
                st.metric("è³ªå•ã‚³ãƒ¡ãƒ³ãƒˆä»¶æ•°", question_stats["total_questions"])
                st.metric("è³ªå•å›ç­”ç‡", f"{question_stats['answer_rate']:.1f}%")
            else:
                st.info("è³ªå•ã‚³ãƒ¡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            st.write("**ãƒãƒ£ãƒƒãƒˆæ„Ÿæƒ…åˆ¥ä»¶æ•°**")
            for sentiment, count in stats["sentiment_counts"].items():
                st.write(f"- {sentiment}: {count}ä»¶")
        
        st.markdown("---")
        
        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ï¼ˆåˆ†æå®Œäº†æ™‚ã«è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ï¼‰
        st.subheader("ğŸ“¥ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¤‰æ›´ã—ãŸã„å ´åˆã®å…¥åŠ›æ¬„ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        uploaded_filename_base = st.session_state.get("uploaded_csv_filename", "")
        if uploaded_filename_base:
            default_file_title = f"ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æ_{uploaded_filename_base}"
        else:
            default_file_title = "ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æ"
        
        file_title = st.text_input(
            "ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¤‰æ›´ï¼ˆæ‹¡å¼µå­ãªã—ã€å¤‰æ›´ã—ãªã„å ´åˆã¯ãã®ã¾ã¾ï¼‰",
            value=default_file_title,
            key="csv_filename_input"
        )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯ã€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿæˆ
        if file_title and ("csv_main_filename" not in st.session_state or 
                          not st.session_state.csv_main_filename or 
                          file_title not in st.session_state.csv_main_filename):
            try:
                # ãƒ¡ã‚¤ãƒ³CSVï¼ˆå…¨ã‚³ãƒ¡ãƒ³ãƒˆï¼‰ã‚’å†ç”Ÿæˆ
                # guest_idã‚’å‰Šé™¤ã—ã€inserted_atã‚’ã€Œé…ä¿¡æ™‚é–“ã€ã«ãƒªãƒãƒ¼ãƒ ã—ã¦ä¸€ç•ªå·¦åˆ—ã«ç§»å‹•
                main_df = df.copy()
                
                # å›ç­”æ–¹æ³•ãŒnanã®å ´åˆã®å‡¦ç†
                if 'å›ç­”æ–¹æ³•' in main_df.columns:
                    nan_mask = main_df['å›ç­”æ–¹æ³•'].isna() | (main_df['å›ç­”æ–¹æ³•'].astype(str).str.strip() == 'nan')
                    if 'å›ç­”çŠ¶æ³' in main_df.columns:
                        main_df.loc[nan_mask, 'å›ç­”çŠ¶æ³'] = False
                    main_df.loc[nan_mask, 'å›ç­”æ–¹æ³•'] = ''
                
                if 'guest_id' in main_df.columns:
                    main_df = main_df.drop(columns=['guest_id'])
                if 'inserted_at' in main_df.columns:
                    main_df = main_df.rename(columns={'inserted_at': 'é…ä¿¡æ™‚é–“'})
                    # é…ä¿¡æ™‚é–“ã‚’ä¸€ç•ªå·¦åˆ—ã«ç§»å‹•
                    cols = ['é…ä¿¡æ™‚é–“'] + [col for col in main_df.columns if col != 'é…ä¿¡æ™‚é–“']
                    main_df = main_df[cols]
                
                # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
                csv_main = add_statistics_to_csv(main_df, stats, is_question=False)
                st.session_state.csv_main_data = csv_main.encode('utf-8-sig')
                st.session_state.csv_main_filename = f"{file_title}_ãƒ¡ã‚¤ãƒ³.csv"
                
                # è³ªå•CSVï¼ˆè³ªå•ã‚³ãƒ¡ãƒ³ãƒˆã®ã¿ï¼‰ã‚’å†ç”Ÿæˆ
                if len(question_df) > 0:
                    # guest_idã‚’å‰Šé™¤ã—ã€åˆ—ã®é †åºã‚’èª¿æ•´ï¼ˆAåˆ—: å›ç­”çŠ¶æ³ã€Båˆ—: é…ä¿¡æ™‚é–“ï¼‰
                    question_csv_df = question_df.copy()
                    
                    # å›ç­”æ–¹æ³•ãŒnanã®å ´åˆã®å‡¦ç†
                    if 'å›ç­”æ–¹æ³•' in question_csv_df.columns:
                        nan_mask = question_csv_df['å›ç­”æ–¹æ³•'].isna() | (question_csv_df['å›ç­”æ–¹æ³•'].astype(str).str.strip() == 'nan')
                        if 'å›ç­”çŠ¶æ³' in question_csv_df.columns:
                            question_csv_df.loc[nan_mask, 'å›ç­”çŠ¶æ³'] = False
                        question_csv_df.loc[nan_mask, 'å›ç­”æ–¹æ³•'] = ''
                    
                    if 'guest_id' in question_csv_df.columns:
                        question_csv_df = question_csv_df.drop(columns=['guest_id'])
                    if 'inserted_at' in question_csv_df.columns:
                        question_csv_df = question_csv_df.rename(columns={'inserted_at': 'é…ä¿¡æ™‚é–“'})
                    # åˆ—ã®é †åº: å›ç­”çŠ¶æ³ã€é…ä¿¡æ™‚é–“ã€ãã®ä»–
                    if 'å›ç­”çŠ¶æ³' in question_csv_df.columns and 'é…ä¿¡æ™‚é–“' in question_csv_df.columns:
                        other_cols = [col for col in question_csv_df.columns if col not in ['å›ç­”çŠ¶æ³', 'é…ä¿¡æ™‚é–“']]
                        cols = ['å›ç­”çŠ¶æ³', 'é…ä¿¡æ™‚é–“'] + other_cols
                        question_csv_df = question_csv_df[cols]
                    
                    # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
                    csv_question = add_statistics_to_csv(question_csv_df, stats, is_question=True, question_stats=question_stats)
                    st.session_state.csv_question_data = csv_question.encode('utf-8-sig')
                    st.session_state.csv_question_filename = f"{file_title}_è³ªå•.csv"
            except Exception as e:
                st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        # ãƒ¡ã‚¤ãƒ³CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯
        if "csv_main_data" in st.session_state and st.session_state.csv_main_data:
            download_link = create_download_link(
                st.session_state.csv_main_data,
                st.session_state.csv_main_filename,
                "text/csv"
            )
            st.markdown(f"**ãƒ¡ã‚¤ãƒ³CSVï¼ˆå…¨ã‚³ãƒ¡ãƒ³ãƒˆï¼‰**: {download_link}", unsafe_allow_html=True)
        else:
            st.warning("âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        
        # è³ªå•CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ï¼ˆè³ªå•ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
        if len(question_df) > 0:
            if "csv_question_data" in st.session_state and st.session_state.csv_question_data:
                download_link = create_download_link(
                    st.session_state.csv_question_data,
                    st.session_state.csv_question_filename,
                    "text/csv"
                )
                st.markdown(f"**è³ªå•CSVï¼ˆè³ªå•ã‚³ãƒ¡ãƒ³ãƒˆã®ã¿ï¼‰**: {download_link}", unsafe_allow_html=True)
            else:
                st.info("ğŸ’¡ è³ªå•CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­...")
                try:
                    # guest_idã‚’å‰Šé™¤ã—ã€åˆ—ã®é †åºã‚’èª¿æ•´ï¼ˆAåˆ—: å›ç­”çŠ¶æ³ã€Båˆ—: é…ä¿¡æ™‚é–“ï¼‰
                    question_csv_df = question_df.copy()
                    
                    # å›ç­”æ–¹æ³•ãŒnanã®å ´åˆã®å‡¦ç†
                    if 'å›ç­”æ–¹æ³•' in question_csv_df.columns:
                        nan_mask = question_csv_df['å›ç­”æ–¹æ³•'].isna() | (question_csv_df['å›ç­”æ–¹æ³•'].astype(str).str.strip() == 'nan')
                        if 'å›ç­”çŠ¶æ³' in question_csv_df.columns:
                            question_csv_df.loc[nan_mask, 'å›ç­”çŠ¶æ³'] = False
                        question_csv_df.loc[nan_mask, 'å›ç­”æ–¹æ³•'] = ''
                    
                    if 'guest_id' in question_csv_df.columns:
                        question_csv_df = question_csv_df.drop(columns=['guest_id'])
                    if 'inserted_at' in question_csv_df.columns:
                        question_csv_df = question_csv_df.rename(columns={'inserted_at': 'é…ä¿¡æ™‚é–“'})
                    # åˆ—ã®é †åº: å›ç­”çŠ¶æ³ã€é…ä¿¡æ™‚é–“ã€ãã®ä»–
                    if 'å›ç­”çŠ¶æ³' in question_csv_df.columns and 'é…ä¿¡æ™‚é–“' in question_csv_df.columns:
                        other_cols = [col for col in question_csv_df.columns if col not in ['å›ç­”çŠ¶æ³', 'é…ä¿¡æ™‚é–“']]
                        cols = ['å›ç­”çŠ¶æ³', 'é…ä¿¡æ™‚é–“'] + other_cols
                        question_csv_df = question_csv_df[cols]
                    # çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
                    csv_question = add_statistics_to_csv(question_csv_df, stats, is_question=True, question_stats=question_stats)
                    st.session_state.csv_question_data = csv_question.encode('utf-8-sig')
                    st.session_state.csv_question_filename = f"{file_title}_è³ªå•.csv"
                    download_link = create_download_link(
                        st.session_state.csv_question_data,
                        st.session_state.csv_question_filename,
                        "text/csv"
                    )
                    st.markdown(f"**è³ªå•CSVï¼ˆè³ªå•ã‚³ãƒ¡ãƒ³ãƒˆã®ã¿ï¼‰**: {download_link}", unsafe_allow_html=True)
                except Exception as e:
                    st.error(f"è³ªå•CSVãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: gray;'>
        <p>ãƒ©ã‚¤ãƒ–é…ä¿¡ãƒãƒ£ãƒƒãƒˆåˆ†æãƒ„ãƒ¼ãƒ« v1.0</p>
        </div>
        """,
        unsafe_allow_html=True
    )


def show_question_answer_page():
    """è³ªå•å›ç­”åˆ¤å®šæ©Ÿèƒ½ã®ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    st.header("ğŸ“ è³ªå•å›ç­”åˆ¤å®šæ©Ÿèƒ½")
    st.info("è³ªå•CSVã«å¯¾ã—ã¦å›ç­”çŠ¶æ³ã‚’åˆ¤å®šã—ã¾ã™ã€‚æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨äººé–“ãŒåˆ¤å®šã—ãŸCSVãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
    if "question_csv_data" not in st.session_state:
        st.session_state.question_csv_data = None
    if "question_answer_result" not in st.session_state:
        st.session_state.question_answer_result = None
    if "question_answer_csv_data" not in st.session_state:
        st.session_state.question_answer_csv_data = None
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.subheader("1. ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    st.info("ğŸ’¡ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã‚¢ãƒ³ãƒ‰ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ã‹ã€ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    
    # ç¸¦åˆ—ã§ä¸¦ã¹ã‚‹
    transcript_file = st.file_uploader(
        "ğŸ“„ æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—å¯ï¼‰",
        type=["txt", "csv"],
        key="transcript_upload",
        help="æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã‚¢ãƒ³ãƒ‰ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ã‹ã€ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚"
    )
    
    manual_csv_file = st.file_uploader(
        "ğŸ“Š äººé–“ãŒåˆ¤å®šã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—å¯ï¼‰",
        type=["csv"],
        key="manual_csv_upload",
        help="äººé–“ãŒåˆ¤å®šã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã‚¢ãƒ³ãƒ‰ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ã‹ã€ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚"
    )
    
    question_file = st.file_uploader(
        "â“ è³ªå•CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—å¯ï¼‰",
        type=["csv"],
        key="question_csv_upload",
        help="è³ªå•CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ã‚¢ãƒ³ãƒ‰ãƒ‰ãƒ­ãƒƒãƒ—ã™ã‚‹ã‹ã€ã‚¯ãƒªãƒƒã‚¯ã—ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚"
    )
    
    # åˆ¤å®šé–‹å§‹ãƒœã‚¿ãƒ³ï¼ˆè³ªå•CSVã¯å¿…é ˆã€ä»–ã®2ã¤ã¯ã©ã¡ã‚‰ã‹1ã¤ä»¥ä¸Šå¿…è¦ï¼‰
    if question_file:
        if transcript_file or manual_csv_file:
            if st.button("åˆ¤å®šã‚’é–‹å§‹", type="primary"):
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_question:
                        tmp_question.write(question_file.getvalue())
                        question_path = tmp_question.name
                    
                    transcript_path = None
                    manual_path = None
                    
                    if transcript_file:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".txt") as tmp_transcript:
                            tmp_transcript.write(transcript_file.getvalue())
                            transcript_path = tmp_transcript.name
                    
                    if manual_csv_file:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as tmp_manual:
                            tmp_manual.write(manual_csv_file.getvalue())
                            manual_path = tmp_manual.name
                    
                    # åˆ¤å®šå‡¦ç†
                    with st.spinner("å›ç­”çŠ¶æ³ã‚’åˆ¤å®šä¸­..."):
                        from utils.transcript_parser import parse_transcript
                        from utils.question_answer_matcher import match_questions_with_transcript, match_questions_with_manual_csv
                        
                        # è³ªå•CSVã‚’èª­ã¿è¾¼ã¿
                        question_df = pd.read_csv(question_path, encoding='utf-8-sig')
                        result_df = question_df.copy()
                        
                        # å›ç­”çŠ¶æ³åˆ—ã¨å›ç­”æ–¹æ³•åˆ—ã‚’åˆæœŸåŒ–
                        result_df['å›ç­”çŠ¶æ³'] = False
                        result_df['å›ç­”æ–¹æ³•'] = ''
                        
                        # æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰åˆ¤å®š
                        transcript_data = None
                        if transcript_path:
                            # æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ‘ãƒ¼ã‚¹
                            transcript_data = parse_transcript(transcript_path)
                            
                            # ãƒ‘ãƒ¼ã‚¹çµæœã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
                            if len(transcript_data) > 0:
                                st.success(f"âœ… æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ãƒ¼ã‚¹æˆåŠŸ: {len(transcript_data)}ä»¶ã®å›ç­”ç®‡æ‰€ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
                                
                                # è©±è€…ã”ã¨ã®çµ±è¨ˆ
                                speaker_counts = {}
                                for answer in transcript_data:
                                    speaker = answer.get('speaker', 'ä¸æ˜')
                                    speaker_counts[speaker] = speaker_counts.get(speaker, 0) + 1
                                
                                if speaker_counts:
                                    speaker_info = ", ".join([f"{speaker}: {count}ä»¶" for speaker, count in speaker_counts.items()])
                                    st.info(f"ğŸ“Š è©±è€…åˆ¥ã®å›ç­”æ•°: {speaker_info}")
                            else:
                                st.warning("âš ï¸ æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å›ç­”ç®‡æ‰€ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                            
                            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®3ä»¶ï¼‰
                            if len(transcript_data) > 0:
                                with st.expander("ğŸ” æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®3ä»¶ï¼‰"):
                                    for i, answer in enumerate(transcript_data[:3]):
                                        st.text(f"ã€{i+1}ã€‘è©±è€…: {answer.get('speaker', 'N/A')}, é–‹å§‹æ™‚é–“: {answer.get('start_time', 'N/A')}, çµ‚äº†æ™‚é–“: {answer.get('end_time', 'N/A')}")
                                        st.text(f"å†…å®¹: {answer.get('text', '')[:100]}...")
                                        st.text("---")
                            
                            # è³ªå•ã¨å›ç­”ã‚’ç…§åˆ
                            transcript_result = match_questions_with_transcript(question_df, transcript_data)
                            
                            # ç…§åˆçµæœã®çµ±è¨ˆ
                            transcript_matched = transcript_result['å›ç­”çŠ¶æ³'].sum()
                            st.info(f"âœ… æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®ç…§åˆ: {transcript_matched}ä»¶ã®è³ªå•ãŒå›ç­”æ¸ˆã¿ã¨ã—ã¦åˆ¤å®šã•ã‚Œã¾ã—ãŸ")
                            
                            # ç…§åˆå¤±æ•—ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
                            if transcript_matched == 0:
                                st.warning("âš ï¸ ç…§åˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã®ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                            
                            # çµæœã‚’çµ±åˆï¼ˆå›ç­”çŠ¶æ³ãŒTRUEã®å ´åˆã¯ä¸Šæ›¸ãã€å›ç­”æ–¹æ³•ã‚‚æ›´æ–°ï¼‰
                            for idx in result_df.index:
                                if transcript_result.at[idx, 'å›ç­”çŠ¶æ³']:
                                    result_df.at[idx, 'å›ç­”çŠ¶æ³'] = True
                                    result_df.at[idx, 'å›ç­”æ–¹æ³•'] = transcript_result.at[idx, 'å›ç­”æ–¹æ³•']
                        
                        # äººé–“ãŒåˆ¤å®šã—ãŸCSVã‹ã‚‰åˆ¤å®š
                        if manual_path:
                            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’è‡ªå‹•æ¤œå‡ºã™ã‚‹é–¢æ•°
                            def detect_manual_csv_header(file_path: str, expected_columns: list = None) -> int:
                                """äººé–“ãŒåˆ¤å®šã—ãŸCSVã®ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¤œå‡º"""
                                if expected_columns is None:
                                    # ã€Œå›ç­”æ¸ˆã€ã¨ã€Œå›ç­”æ¸ˆã¿ã€ã®ä¸¡æ–¹ã‚’æ¤œç´¢å¯¾è±¡ã«å«ã‚ã‚‹
                                    expected_columns = ['å›ç­”æ¸ˆã¿', 'å›ç­”æ¸ˆ', 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼å', 'è³ªå•', 'å›ç­”æ–¹æ³•', 'å›ç­”']
                                
                                try:
                                    with open(file_path, 'r', encoding='utf-8-sig') as f:
                                        lines = f.readlines()
                                    
                                    # æœ€åˆã®10è¡Œã‚’ãƒã‚§ãƒƒã‚¯
                                    for row_idx in range(min(10, len(lines))):
                                        line = lines[row_idx].strip()
                                        # ã‚¿ãƒ–åŒºåˆ‡ã‚Šã¨ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ä¸¡æ–¹ã‚’è©¦ã™
                                        for sep in ['\t', ',']:
                                            columns = [col.strip() for col in line.split(sep)]
                                            # ã€Œè³ªå•ã€åˆ—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªï¼ˆæœ€å„ªå…ˆï¼‰
                                            if 'è³ªå•' in columns:
                                                # æœŸå¾…ã•ã‚Œã‚‹åˆ—åãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚‚ç¢ºèª
                                                if any(col in columns for col in expected_columns):
                                                    print(f"DEBUG: ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¤œå‡º - è¡Œ{row_idx}: {columns}", file=sys.stderr)
                                                    return row_idx
                                except Exception as e:
                                    print(f"DEBUG: ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
                                    pass
                                return 0  # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯0è¡Œç›®ã‚’è¿”ã™
                            
                            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¤œå‡º
                            header_row = detect_manual_csv_header(manual_path)
                            st.info(f"DEBUG: æ¤œå‡ºã•ã‚ŒãŸãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ: {header_row}è¡Œç›®ï¼ˆ0å§‹ã¾ã‚Šãªã®ã§ã€å®Ÿéš›ã¯{header_row+1}è¡Œç›®ï¼‰")
                            
                            # æ¤œå‡ºã•ã‚ŒãŸãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®å®Ÿéš›ã®å†…å®¹ã‚’è¡¨ç¤º
                            try:
                                with open(manual_path, 'r', encoding='utf-8-sig') as f:
                                    lines = f.readlines()
                                    if header_row < len(lines):
                                        header_line = lines[header_row].strip()
                                        st.info(f"DEBUG: æ¤œå‡ºã•ã‚ŒãŸãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®å†…å®¹: {header_line}")
                            except Exception as e:
                                st.warning(f"DEBUG: ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {e}")
                            
                            # åŒºåˆ‡ã‚Šæ–‡å­—ã‚’è‡ªå‹•æ¤œå‡ºã™ã‚‹é–¢æ•°
                            def detect_delimiter(file_path: str, header_row: int) -> str:
                                """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®åŒºåˆ‡ã‚Šæ–‡å­—ã‚’è‡ªå‹•æ¤œå‡º"""
                                try:
                                    with open(file_path, 'r', encoding='utf-8-sig') as f:
                                        lines = f.readlines()
                                    
                                    if header_row < len(lines):
                                        header_line = lines[header_row].strip()
                                        
                                        # ã‚¿ãƒ–ã¨ã‚«ãƒ³ãƒã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                                        tab_count = header_line.count('\t')
                                        comma_count = header_line.count(',')
                                        
                                        print(f"DEBUG: åŒºåˆ‡ã‚Šæ–‡å­—æ¤œå‡º - ã‚¿ãƒ–æ•°: {tab_count}, ã‚«ãƒ³ãƒæ•°: {comma_count}", file=sys.stderr)
                                        
                                        # ã‚ˆã‚Šå¤šã„æ–¹ã‚’åŒºåˆ‡ã‚Šæ–‡å­—ã¨ã—ã¦ä½¿ç”¨
                                        if tab_count > comma_count and tab_count > 0:
                                            print("DEBUG: ã‚¿ãƒ–åŒºåˆ‡ã‚Šã‚’æ¤œå‡º", file=sys.stderr)
                                            return '\t'
                                        elif comma_count > 0:
                                            print("DEBUG: ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã‚’æ¤œå‡º", file=sys.stderr)
                                            return ','
                                        
                                        # ã©ã¡ã‚‰ã‚‚ãªã„å ´åˆã¯ã€æ¬¡ã®ãƒ‡ãƒ¼ã‚¿è¡Œã‚’ãƒã‚§ãƒƒã‚¯
                                        if header_row + 1 < len(lines):
                                            data_line = lines[header_row + 1].strip()
                                            tab_count = data_line.count('\t')
                                            comma_count = data_line.count(',')
                                            
                                            print(f"DEBUG: ãƒ‡ãƒ¼ã‚¿è¡Œã§åŒºåˆ‡ã‚Šæ–‡å­—æ¤œå‡º - ã‚¿ãƒ–æ•°: {tab_count}, ã‚«ãƒ³ãƒæ•°: {comma_count}", file=sys.stderr)
                                            
                                            if tab_count > comma_count and tab_count > 0:
                                                return '\t'
                                            elif comma_count > 0:
                                                return ','
                                except Exception as e:
                                    print(f"DEBUG: åŒºåˆ‡ã‚Šæ–‡å­—æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
                                    pass
                                
                                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚«ãƒ³ãƒ
                                return ','
                            
                            # åŒºåˆ‡ã‚Šæ–‡å­—ã‚’è‡ªå‹•æ¤œå‡º
                            delimiter = detect_delimiter(manual_path, header_row)
                            
                            # äººé–“ãŒåˆ¤å®šã—ãŸCSVã‚’èª­ã¿è¾¼ã¿
                            try:
                                manual_df = pd.read_csv(
                                    manual_path, 
                                    encoding='utf-8-sig', 
                                    sep=delimiter, 
                                    header=header_row,
                                    skipinitialspace=True,
                                    on_bad_lines='skip'  # ä¸æ­£ãªè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                                )
                                
                                print(f"DEBUG: CSVèª­ã¿è¾¼ã¿æˆåŠŸã€‚åŒºåˆ‡ã‚Šæ–‡å­—: {repr(delimiter)}, åˆ—æ•°: {len(manual_df.columns)}, è¡Œæ•°: {len(manual_df)}", file=sys.stderr)
                                st.info(f"DEBUG: CSVèª­ã¿è¾¼ã¿æˆåŠŸã€‚åŒºåˆ‡ã‚Šæ–‡å­—: {repr(delimiter)}, åˆ—æ•°: {len(manual_df.columns)}, è¡Œæ•°: {len(manual_df)}")
                                st.info(f"DEBUG: åˆ—å: {list(manual_df.columns)}")
                                
                                # åˆ—ãŒ1ã¤ã—ã‹ãªã„å ´åˆã¯ã€æ‰‹å‹•ã§åˆ†å‰²ã‚’è©¦ã¿ã‚‹
                                if len(manual_df.columns) == 1:
                                    st.warning("âš ï¸ CSVãŒæ­£ã—ããƒ‘ãƒ¼ã‚¹ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚æ‰‹å‹•ã§åˆ†å‰²ã‚’è©¦ã¿ã¾ã™...")
                                    
                                    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’èª­ã¿è¾¼ã‚“ã§åˆ—åã‚’å–å¾—
                                    with open(manual_path, 'r', encoding='utf-8-sig') as f:
                                        lines = f.readlines()
                                        header_line = lines[header_row].strip()
                                        
                                        # ã‚«ãƒ³ãƒã¨ã‚¿ãƒ–ã®ä¸¡æ–¹ã§è©¦ã™
                                        if ',' in header_line:
                                            new_columns = [col.strip() for col in header_line.split(',')]
                                            delimiter = ','
                                        elif '\t' in header_line:
                                            new_columns = [col.strip() for col in header_line.split('\t')]
                                            delimiter = '\t'
                                        else:
                                            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚«ãƒ³ãƒ
                                            new_columns = [col.strip() for col in header_line.split(',')]
                                            delimiter = ','
                                    
                                    print(f"DEBUG: æ‰‹å‹•åˆ†å‰²ã‚’è©¦ã¿ã¾ã™ã€‚åŒºåˆ‡ã‚Šæ–‡å­—: {repr(delimiter)}, åˆ—æ•°: {len(new_columns)}", file=sys.stderr)
                                    
                                    # ãƒ‡ãƒ¼ã‚¿ã‚’å†èª­ã¿è¾¼ã¿ï¼ˆåˆ—åã‚’æ‰‹å‹•æŒ‡å®šï¼‰
                                    manual_df = pd.read_csv(
                                        manual_path,
                                        encoding='utf-8-sig',
                                        sep=delimiter,
                                        header=None,
                                        skiprows=header_row + 1,
                                        names=new_columns,
                                        skipinitialspace=True,
                                        on_bad_lines='skip'
                                    )
                                    
                                    print(f"DEBUG: æ‰‹å‹•åˆ†å‰²æˆåŠŸã€‚åˆ—æ•°: {len(manual_df.columns)}, è¡Œæ•°: {len(manual_df)}", file=sys.stderr)
                                    st.info(f"DEBUG: æ‰‹å‹•åˆ†å‰²æˆåŠŸã€‚åˆ—æ•°: {len(manual_df.columns)}, åˆ—å: {list(manual_df.columns)}")
                                
                            except Exception as e:
                                st.error(f"âŒ CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                                print(f"DEBUG: CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
                                st.exception(e)
                                manual_df = None  # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯å¾Œç¶šã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
                            
                            # manual_dfãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚ŒãŸå ´åˆã®ã¿å‡¦ç†ã‚’ç¶šè¡Œ
                            if manual_df is None:
                                st.error("âŒ CSVã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸãŸã‚ã€äººé–“ãŒåˆ¤å®šã—ãŸCSVã‹ã‚‰ã®ç…§åˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            else:
                                st.info(f"ğŸ“‹ åˆ—å: {', '.join(manual_df.columns.tolist())}")
                                
                                # ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤ºï¼ˆæœ€åˆã®5è¡Œï¼‰
                                with st.expander("ğŸ” èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®5è¡Œï¼‰"):
                                    st.dataframe(manual_df.head(5), use_container_width=True)
                                
                                # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼: å›ç­”æ¸ˆåˆ—ã®å€¤ã®åˆ†å¸ƒã‚’è¡¨ç¤º
                                answered_col = None
                                if 'å›ç­”æ¸ˆ' in manual_df.columns:
                                    answered_col = 'å›ç­”æ¸ˆ'
                                elif 'å›ç­”æ¸ˆã¿' in manual_df.columns:
                                    answered_col = 'å›ç­”æ¸ˆã¿'
                                
                                if answered_col:
                                    value_counts = manual_df[answered_col].value_counts()
                                    st.info(f"ğŸ“ˆ å›ç­”æ¸ˆåˆ—ã®å€¤ã®åˆ†å¸ƒ: {dict(value_counts)}")
                                    
                                    # TRUEã®è¡Œã®è³ªå•ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤ºï¼ˆæœ€åˆã®5ä»¶ï¼‰
                                    true_rows = manual_df[manual_df[answered_col].astype(str).str.upper().isin(['TRUE', '1', 'T', 'YES', 'Y'])]
                                    if len(true_rows) > 0:
                                        question_col = None
                                        for col in ['è³ªå•', 'original_text', 'ã‚³ãƒ¡ãƒ³ãƒˆ', 'text']:
                                            if col in manual_df.columns:
                                                question_col = col
                                                break
                                        if question_col:
                                            st.info(f"âœ… å›ç­”æ¸ˆã¿ï¼ˆTRUEï¼‰ã®è³ªå•æ•°: {len(true_rows)}ä»¶")
                                            with st.expander("ğŸ” å›ç­”æ¸ˆã¿ï¼ˆTRUEï¼‰ã®è³ªå•ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®5ä»¶ï¼‰"):
                                                st.dataframe(true_rows[[answered_col, question_col]].head(5), use_container_width=True)
                                else:
                                    st.warning("âš ï¸ ã€Œå›ç­”æ¸ˆã€ã¾ãŸã¯ã€Œå›ç­”æ¸ˆã¿ã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                                
                                # è³ªå•ã¨å›ç­”ã‚’ç…§åˆï¼ˆæ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æ¸¡ã™ï¼‰
                                if transcript_data:
                                    st.info(f"ğŸ“ æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚‚å‚ç…§ã—ã¦ç…§åˆã—ã¾ã™ï¼ˆ{len(transcript_data)}ä»¶ã®å›ç­”ç®‡æ‰€ï¼‰")
                                
                                manual_result = match_questions_with_manual_csv(question_df, manual_df, transcript_data)
                                
                                # ç…§åˆçµæœã®çµ±è¨ˆ
                                manual_matched = manual_result['å›ç­”çŠ¶æ³'].sum()
                                st.info(f"âœ… äººé–“ãŒåˆ¤å®šã—ãŸCSVã‹ã‚‰ã®ç…§åˆ: {manual_matched}ä»¶ã®è³ªå•ãŒå›ç­”æ¸ˆã¿ã¨ã—ã¦åˆ¤å®šã•ã‚Œã¾ã—ãŸ")
                                
                                # ç…§åˆå¤±æ•—ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
                                if manual_matched == 0:
                                    st.warning("âš ï¸ ç…§åˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã®ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                                
                                # ç…§åˆçµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®5ä»¶ï¼‰
                                if manual_matched > 0:
                                    matched_preview = manual_result[manual_result['å›ç­”çŠ¶æ³']].head(5)
                                    with st.expander("ğŸ” ç…§åˆæˆåŠŸã—ãŸè³ªå•ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®5ä»¶ï¼‰"):
                                        st.dataframe(matched_preview[['å›ç­”çŠ¶æ³', 'å›ç­”æ–¹æ³•'] + [col for col in matched_preview.columns if col not in ['å›ç­”çŠ¶æ³', 'å›ç­”æ–¹æ³•']]], use_container_width=True)
                                
                                # çµæœã‚’çµ±åˆï¼ˆå›ç­”çŠ¶æ³ãŒTRUEã®å ´åˆã¯ä¸Šæ›¸ãã€å›ç­”æ–¹æ³•ã‚‚æ›´æ–°ï¼‰
                                for idx in result_df.index:
                                    if manual_result.at[idx, 'å›ç­”çŠ¶æ³']:
                                        result_df.at[idx, 'å›ç­”çŠ¶æ³'] = True
                                        # å›ç­”æ–¹æ³•ãŒæ—¢ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯çµ±åˆï¼ˆé‹å–¶ã‚³ãƒ¡ãƒ³ãƒˆã‚’å„ªå…ˆï¼‰
                                        if manual_result.at[idx, 'å›ç­”æ–¹æ³•']:
                                            result_df.at[idx, 'å›ç­”æ–¹æ³•'] = manual_result.at[idx, 'å›ç­”æ–¹æ³•']
                                        elif not result_df.at[idx, 'å›ç­”æ–¹æ³•']:
                                            result_df.at[idx, 'å›ç­”æ–¹æ³•'] = 'é‹å–¶ã‚³ãƒ¡ãƒ³ãƒˆ'
                        
                        # åˆ—ã®é †åºã‚’èª¿æ•´ï¼ˆå›ç­”çŠ¶æ³ã‚’ä¸€ç•ªå·¦åˆ—ã€å›ç­”æ–¹æ³•ã‚’å³éš£ã«ï¼‰
                        cols = ['å›ç­”çŠ¶æ³', 'å›ç­”æ–¹æ³•'] + [col for col in result_df.columns if col not in ['å›ç­”çŠ¶æ³', 'å›ç­”æ–¹æ³•']]
                        result_df = result_df[cols]
                        
                        # CSVç”Ÿæˆå‰ã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å…¨ä½“ã§nanã‚’å‡¦ç†
                        # ã™ã¹ã¦ã®åˆ—ã§NaNå€¤ã‚’ç©ºæ–‡å­—åˆ—ã«å¤‰æ›
                        result_df = result_df.fillna('')
                        
                        # æ–‡å­—åˆ—ã¨ã—ã¦"nan"ãŒå…¥ã£ã¦ã„ã‚‹å ´åˆã‚‚ç©ºæ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„ï¼‰
                        for col in result_df.columns:
                            if result_df[col].dtype == 'object':  # æ–‡å­—åˆ—å‹ã®åˆ—ã®ã¿å‡¦ç†
                                result_df[col] = result_df[col].astype(str).str.strip()
                                nan_strings = ['nan', 'NaN', 'NAN', 'None', 'none', 'NONE', 'null', 'NULL', 'Null']
                                for nan_str in nan_strings:
                                    result_df.loc[result_df[col] == nan_str, col] = ''
                        
                        # å›ç­”æ–¹æ³•ãŒç©ºæ–‡å­—åˆ—ã®å ´åˆã€å›ç­”çŠ¶æ³ã‚’Falseã«è¨­å®š
                        if 'å›ç­”æ–¹æ³•' in result_df.columns and 'å›ç­”çŠ¶æ³' in result_df.columns:
                            empty_mask = result_df['å›ç­”æ–¹æ³•'] == ''
                            result_df.loc[empty_mask, 'å›ç­”çŠ¶æ³'] = False
                        
                        # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                        st.session_state.question_answer_result = result_df
                        
                        # CSVã‚’ç”Ÿæˆ
                        csv_data = generate_question_answer_csv(result_df)
                        st.session_state.question_answer_csv_data = csv_data.encode('utf-8-sig')
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    os.unlink(question_path)
                    if transcript_path:
                        os.unlink(transcript_path)
                    if manual_path:
                        os.unlink(manual_path)
                    
                    st.success("âœ“ åˆ¤å®šãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    import traceback
                    with st.expander("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±"):
                        st.code(traceback.format_exc())
        else:
            st.warning("âš ï¸ æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯äººé–“ãŒåˆ¤å®šã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã„ãšã‚Œã‹ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.info("ğŸ’¡ è³ªå•CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    
    # çµæœã®è¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if st.session_state.question_answer_result is not None:
        st.markdown("---")
        st.subheader("3. çµæœã®ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        
        result_df = st.session_state.question_answer_result
        
        # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
        total_questions = len(result_df)
        answered_count = result_df['å›ç­”çŠ¶æ³'].sum() if 'å›ç­”çŠ¶æ³' in result_df.columns else 0
        answer_rate = (answered_count / total_questions * 100) if total_questions > 0 else 0.0
        
        # å›ç­”æ–¹æ³•åˆ¥ã®çµ±è¨ˆ
        answer_method_counts = {}
        if 'å›ç­”æ–¹æ³•' in result_df.columns:
            answered_df_for_stats = result_df[result_df['å›ç­”çŠ¶æ³']]
            if len(answered_df_for_stats) > 0:
                answer_method_counts = answered_df_for_stats['å›ç­”æ–¹æ³•'].value_counts().to_dict()
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
        col1, col2 = st.columns(2)
        with col1:
            st.metric("è³ªå•å›ç­”ç‡", f"{answer_rate:.1f}%")
        with col2:
            st.metric("å›ç­”ä»¶æ•°", f"{answered_count}ä»¶")
        
        # å›ç­”æ–¹æ³•åˆ¥ã®çµ±è¨ˆã‚’è¡¨ç¤º
        if answer_method_counts:
            st.subheader("å›ç­”æ–¹æ³•åˆ¥ã®å†…è¨³")
            for method, count in answer_method_counts.items():
                st.write(f"- {method}: {count}ä»¶")
        
        # çµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        st.subheader("çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        
        # ã‚¿ãƒ–ã§å›ç­”æ¸ˆã¿ã¨æœªå›ç­”ã‚’åˆ†ã‘ã¦è¡¨ç¤º
        tab1, tab2, tab3 = st.tabs(["ã™ã¹ã¦", "å›ç­”æ¸ˆã¿", "æœªå›ç­”"])
        
        with tab1:
            st.dataframe(result_df.head(20), use_container_width=True)
        
        with tab2:
            answered_df = result_df[result_df['å›ç­”çŠ¶æ³']]
            if len(answered_df) > 0:
                st.dataframe(answered_df.head(20), use_container_width=True)
            else:
                st.info("å›ç­”æ¸ˆã¿ã®è³ªå•ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
        with tab3:
            unanswered_df = result_df[~result_df['å›ç­”çŠ¶æ³']]
            if len(unanswered_df) > 0:
                st.dataframe(unanswered_df.head(20), use_container_width=True)
            else:
                st.info("æœªå›ç­”ã®è³ªå•ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯
        if st.session_state.question_answer_csv_data:
            download_link = create_download_link(
                st.session_state.question_answer_csv_data,
                "è³ªå•å›ç­”ã¾ã¨ã‚.csv",
                "text/csv"
            )
            st.markdown(f"**ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: {download_link}", unsafe_allow_html=True)


def generate_question_answer_csv(df: pd.DataFrame) -> str:
    """
    è³ªå•å›ç­”åˆ¤å®šçµæœã®CSVã‚’ç”Ÿæˆï¼ˆçµ±è¨ˆæƒ…å ±ä»˜ãï¼‰
    
    Args:
        df: çµæœãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        
    Returns:
        CSVæ–‡å­—åˆ—
    """
    # inserted_atã‚’é…ä¿¡æ™‚é–“ã«ãƒªãƒãƒ¼ãƒ 
    result_df = df.copy()
    if 'inserted_at' in result_df.columns:
        result_df = result_df.rename(columns={'inserted_at': 'é…ä¿¡æ™‚é–“'})
    
    # å›ç­”æ–¹æ³•ãŒnanã®å ´åˆã®å‡¦ç†
    if 'å›ç­”æ–¹æ³•' in result_df.columns:
        # ã¾ãšã€NaNå€¤ã‚’ç©ºæ–‡å­—åˆ—ã«å¤‰æ›
        result_df['å›ç­”æ–¹æ³•'] = result_df['å›ç­”æ–¹æ³•'].fillna('')
        
        # æ–‡å­—åˆ—ã¨ã—ã¦"nan"ãŒå…¥ã£ã¦ã„ã‚‹å ´åˆã‚‚ç©ºæ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„ï¼‰
        result_df['å›ç­”æ–¹æ³•'] = result_df['å›ç­”æ–¹æ³•'].astype(str).str.strip()
        nan_strings = ['nan', 'NaN', 'NAN', 'None', 'none', 'NONE', 'null', 'NULL', 'Null']
        for nan_str in nan_strings:
            result_df.loc[result_df['å›ç­”æ–¹æ³•'] == nan_str, 'å›ç­”æ–¹æ³•'] = ''
        
        # å›ç­”æ–¹æ³•ãŒç©ºæ–‡å­—åˆ—ã®å ´åˆã€å›ç­”çŠ¶æ³ã‚’Falseã«è¨­å®š
        if 'å›ç­”çŠ¶æ³' in result_df.columns:
            empty_mask = result_df['å›ç­”æ–¹æ³•'] == ''
            result_df.loc[empty_mask, 'å›ç­”çŠ¶æ³'] = False
    
    # åˆ—ã®é †åºã‚’èª¿æ•´ï¼ˆå›ç­”çŠ¶æ³ã‚’Aåˆ—ã€é…ä¿¡æ™‚é–“ã‚’Båˆ—ã«ï¼‰
    if 'å›ç­”çŠ¶æ³' in result_df.columns and 'é…ä¿¡æ™‚é–“' in result_df.columns:
        cols = ['å›ç­”çŠ¶æ³', 'é…ä¿¡æ™‚é–“']
        if 'å›ç­”æ–¹æ³•' in result_df.columns:
            cols.append('å›ç­”æ–¹æ³•')
        # æ®‹ã‚Šã®åˆ—ã‚’è¿½åŠ 
        for col in result_df.columns:
            if col not in cols:
                cols.append(col)
        result_df = result_df[cols]
    
    # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
    total_questions = len(result_df)
    answered_count = result_df['å›ç­”çŠ¶æ³'].sum() if 'å›ç­”çŠ¶æ³' in result_df.columns else 0
    answer_rate = (answered_count / total_questions * 100) if total_questions > 0 else 0.0
    
    # çµ±è¨ˆæƒ…å ±ã‚’CSVå½¢å¼ã§ä½œæˆ
    stats_lines = []
    stats_lines.append("çµ±è¨ˆæƒ…å ±")
    stats_lines.append(f"è³ªå•ä»¶æ•°,{total_questions}ä»¶")
    stats_lines.append(f"å›ç­”ä»¶æ•°,{answered_count}ä»¶")
    stats_lines.append(f"è³ªå•å›ç­”ç‡,{answer_rate:.1f}%")
    stats_lines.append("")  # ç©ºè¡Œ
    stats_lines.append("è³ªå•ãƒ‡ãƒ¼ã‚¿")
    
    # çµ±è¨ˆæƒ…å ±ã‚’CSVæ–‡å­—åˆ—ã«å¤‰æ›
    stats_csv = "\n".join(stats_lines)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’CSVæ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆä¿®æ­£ã—ãŸresult_dfã‚’ä½¿ç”¨ã—ã€NaNå€¤ã‚’ç©ºæ–‡å­—åˆ—ã«å¤‰æ›ï¼‰
    data_csv = result_df.to_csv(index=False, na_rep='')
    
    # çµ±è¨ˆæƒ…å ±ã¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
    combined_csv = stats_csv + "\n" + data_csv
    
    return combined_csv


if __name__ == "__main__":
    main()


